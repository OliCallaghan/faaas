@inproceedings{agacheFirecrackerLightweightVirtualization2020,
  title = {Firecracker: {{Lightweight Virtualization}} for {{Serverless Applications}}},
  booktitle = {17th {{USENIX Symposium}} on {{Networked Systems Design}} and {{Implementation}} ({{NSDI}} 20)},
  author = {Agache, Alexandru and Brooker, Marc and Iordache, Alexandra and Liguori, Anthony and Neugebauer, Rolf and Piwonka, Phil and Popa, Diana-Maria},
  date = {2020-02},
  pages = {419--434},
  publisher = {USENIX Association},
  location = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/nsdi20/presentation/agache},
  isbn = {978-1-939133-13-7}
}

@inproceedings{akkusSANDHighPerformanceServerless2018,
  title = {{{SAND}}: {{Towards High-Performance Serverless Computing}}},
  booktitle = {2018 {{USENIX Annual Technical Conference}} ({{USENIX ATC}} 18)},
  author = {Akkus, Istemi Ekin and Chen, Ruichuan and Rimac, Ivica and Stein, Manuel and Satzke, Klaus and Beck, Andre and Aditya, Paarijaat and Hilt, Volker},
  date = {2018-07},
  pages = {923--935},
  publisher = {USENIX Association},
  location = {Boston, MA},
  url = {https://www.usenix.org/conference/atc18/presentation/akkus},
  isbn = {978-1-939133-01-4}
}

@online{allianceCranelift2024,
  title = {Cranelift},
  author = {Alliance, Bytecode},
  date = {2024},
  url = {https://cranelift.dev/}
}

@online{allianceWasmtime2024,
  title = {Wasmtime},
  author = {Alliance, Bytecode},
  date = {2024},
  url = {https://wasmtime.dev/}
}

@online{amazonAWSLambda2024,
  title = {{{AWS Lambda}}},
  author = {{Amazon}},
  date = {2024},
  url = {https://aws.amazon.com/lambda/}
}

@online{amazonAWSStepFunctions2024,
  title = {{{AWS Step Functions}}},
  author = {{Amazon}},
  date = {2024},
  url = {https://aws.amazon.com/step-functions/}
}

@online{amazonFunctionsCallingFunctions2024,
  title = {Functions Calling Functions},
  author = {{Amazon}},
  date = {2024},
  url = {https://docs.aws.amazon.com/lambda/latest/operatorguide/functions-calling-functions.html}
}

@online{amazonScalingPrimeVideo2024,
  title = {Scaling up the {{Prime Video}} Audio/Video Monitoring Service and Reducing Costs by 90\%},
  author = {{Amazon}},
  date = {2024},
  url = {https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90}
}

@online{apacheOpenWhisk2024,
  title = {{{OpenWhisk}}},
  author = {{Apache}},
  date = {2024},
  url = {https://github.com/apache/openwhisk}
}

@online{azureAzureFunctions2024,
  title = {Azure {{Functions}}},
  author = {{Azure}},
  date = {2024},
  url = {https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview}
}

@article{barcelona-ponsStatefulServerlessComputing2022,
  title = {Stateful {{Serverless Computing}} with {{Crucial}}},
  author = {Barcelona-Pons, Daniel and Sutra, Pierre and Sánchez-Artigas, Marc and París, Gerard and García-López, Pedro},
  date = {2022-03},
  journaltitle = {ACM Trans. Softw. Eng. Methodol.},
  volume = {31},
  number = {3},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  issn = {1049-331X},
  doi = {10.1145/3490386},
  url = {https://doi.org/10.1145/3490386},
  abstract = {Serverless computing greatly simplifies the use of cloud resources. In particular, Function-as-a-Service (FaaS) platforms enable programmers to develop applications as individual functions that can run and scale independently. Unfortunately, applications that require fine-grained support for mutable state and synchronization, such as machine learning (ML) and scientific computing, are notoriously hard to build with this new paradigm. In this work, we aim at bridging this gap. We present Crucial, a system to program highly-parallel stateful serverless applications. Crucial retains the simplicity of serverless computing. It is built upon the key insight that FaaS resembles to concurrent programming at the scale of a datacenter. Accordingly, a distributed shared memory layer is the natural answer to the needs for fine-grained state management and synchronization. Crucial allows to port effortlessly a multi-threaded code base to serverless, where it can benefit from the scalability and pay-per-use model of FaaS platforms. We validate Crucial with the help of micro-benchmarks and by considering various stateful applications. Beyond classical parallel tasks (e.g., a Monte Carlo simulation), these applications include representative ML algorithms such as k-means and logistic regression. Our evaluation shows that Crucial obtains superior or comparable performance to Apache Spark at similar cost (18\%–40\% faster). We also use Crucial to port (part of) a state-of-the-art multi-threaded ML library to serverless. The ported application is up to 30\% faster than with a dedicated high-end server. Finally, we attest that Crucial can rival in performance with a single-machine, multi-threaded implementation of a complex coordination problem. Overall, Crucial delivers all these benefits with less than 6\% of changes in the code bases of the evaluated applications.},
  keywords = {FaaS,in-memory,Serverless,stateful,synchronization}
}

@online{bellardQuickJS2024,
  title = {{{QuickJS}}},
  author = {Bellard, Fabrice},
  date = {2024},
  url = {https://bellard.org/quickjs/}
}

@online{BenjaminBlackEC2,
  title = {Benjamin {{Black}} — {{EC2 Origins}}},
  url = {https://blog.b3k.us/2009/01/25/ec2-origins.html},
  urldate = {2024-06-04},
  file = {/Users/oli/Zotero/storage/75JKJXNQ/ec2-origins.html}
}

@article{burckhardtDurableFunctionsSemantics2021,
  title = {Durable Functions: Semantics for Stateful Serverless},
  author = {Burckhardt, Sebastian and Gillum, Chris and Justo, David and Kallas, Konstantinos and McMahon, Connor and Meiklejohn, Christopher S.},
  date = {2021-10},
  journaltitle = {Proc. ACM Program. Lang.},
  volume = {5},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3485510},
  url = {https://doi.org/10.1145/3485510},
  abstract = {Serverless, or Functions-as-a-Service (FaaS), is an increasingly popular paradigm for application development, as it provides implicit elastic scaling and load based billing. However, the weak execution guarantees and intrinsic compute-storage separation of FaaS create serious challenges when developing applications that require persistent state, reliable progress, or synchronization. This has motivated a new generation of serverless frameworks that provide stateful abstractions. For instance, Azure's Durable Functions (DF) programming model enhances FaaS with actors, workflows, and critical sections. As a programming model, DF is interesting because it combines task and actor parallelism, which makes it suitable for a wide range of serverless applications. We describe DF both informally, using examples, and formally, using an idealized high-level model based on the untyped lambda calculus. Next, we demystify how the DF runtime can (1) execute in a distributed unreliable serverless environment with compute-storage separation, yet still conform to the fault-free high-level model, and (2) persist execution progress without requiring checkpointing support by the language runtime. To this end we define two progressively more complex execution models, which contain the compute-storage separation and the record-replay, and prove that they are equivalent to the high-level model.},
  issue = {OOPSLA},
  keywords = {Durable Functions,Programming,Reliable,Serverless,Service Composition,Services,Workflows}
}

@article{burckhardtNetheriteEfficientExecution2022,
  title = {Netherite: Efficient Execution of Serverless Workflows},
  author = {Burckhardt, Sebastian and Chandramouli, Badrish and Gillum, Chris and Justo, David and Kallas, Konstantinos and McMahon, Connor and Meiklejohn, Christopher S. and Zhu, Xiangfeng},
  date = {2022-04},
  journaltitle = {Proc. VLDB Endow.},
  volume = {15},
  number = {8},
  pages = {1591--1604},
  publisher = {VLDB Endowment},
  issn = {2150-8097},
  doi = {10.14778/3529337.3529344},
  url = {https://doi.org/10.14778/3529337.3529344},
  abstract = {Serverless is a popular choice for cloud service architects because it can provide scalability and load-based billing with minimal developer effort. Functions-as-a-service (FaaS) are originally stateless, but emerging frameworks add stateful abstractions. For instance, the widely used Durable Functions (DF) allow developers to write advanced serverless applications, including reliable workflows and actors, in a programming language of choice. DF implicitly and continuosly persists the state and progress of applications, which greatly simplifies development, but can create an IOps bottleneck.To improve efficiency, we introduce Netherite, a novel architecture for executing serverless workflows on an elastic cluster. Netherite groups the numerous application objects into a smaller number of partitions, and pipelines the state persistence of each partition. This improves latency and throughput, as it enables workflow steps to group commit, even if causally dependent. Moreover, Netherite leverages FASTER's hybrid log approach to support larger-than-memory application state, and to enable efficient partition movement between compute hosts.Our evaluation shows that (a) Netherite achieves lower latency and higher throughput than the original DF engine, by more than an order of magnitude in some cases, and (b) that Netherite has lower latency than some commonly used alternatives, like AWS Step Functions or cloud storage triggers.}
}

@inproceedings{caoPolarDBServerlessCloud2021,
  title = {{{PolarDB Serverless}}: {{A Cloud Native Database}} for {{Disaggregated Data Centers}}},
  booktitle = {Proceedings of the 2021 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Cao, Wei and Zhang, Yingqiang and Yang, Xinjun and Li, Feifei and Wang, Sheng and Hu, Qingda and Cheng, Xuntao and Chen, Zongzhi and Liu, Zhenjun and Fang, Jing and Wang, Bo and Wang, Yuhui and Sun, Haiqing and Yang, Ze and Cheng, Zhushi and Chen, Sen and Wu, Jian and Hu, Wei and Zhao, Jianwei and Gao, Yusong and Cai, Songlu and Zhang, Yunyang and Tong, Jiawang},
  date = {2021},
  series = {{{SIGMOD}} '21},
  pages = {2477--2489},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3448016.3457560},
  url = {https://doi.org/10.1145/3448016.3457560},
  abstract = {beginabstract The trend in the DBMS market is to migrate to the cloud for elasticity, high availability, and lower costs. The traditional, monolithic database architecture is difficult to meet these requirements. With the development of high-speed network and new memory technologies, disaggregated data center has become a reality: it decouples various components from monolithic servers into separated resource pools (e.g., compute, memory, and storage) and connects them through a high-speed network. The next generation cloud native databases should be designed for disaggregated data centers. In this paper, we describe the novel architecture of name, which follows thedisaggregation design paradigm: the CPU resource on compute nodes is decoupled from remote memory pool and storage pool. Each resource pool grows or shrinks independently, providing revon-demand provisoning at multiple dimensions while improving reliability. We also design our system to mitigate the inherent penalty brought by resource disaggregation, and introduce optimizations such as optimistic locking and index awared prefetching. Compared to the architecture that uses local resources, name achieves better dynamic resource provisioning capabilities and 5.3 times faster failure recovery speed, while achieving comparable performance. endabstract},
  isbn = {978-1-4503-8343-1},
  venue = {Virtual Event, China},
  keywords = {cloud database,disaggregated data center,shared remote memory,shared storage}
}

@article{chardServerlessSupercomputingHigh2019,
  title = {Serverless {{Supercomputing}}: {{High Performance Function}} as a {{Service}} for {{Science}}},
  author = {Chard, Ryan and Skluzacek, Tyler J. and Li, Zhuozhao and Babuji, Yadu N. and Woodard, Anna and Blaiszik, Ben and Tuecke, Steven and Foster, Ian T. and Chard, Kyle},
  date = {2019},
  journaltitle = {CoRR},
  volume = {abs/1908.04907},
  eprint = {1908.04907},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1908.04907}
}

@inproceedings{copikSeBSServerlessBenchmark2021,
  title = {{{SeBS}}: {{A Serverless Benchmark Suite}} for {{Function-as-a-Service Computing}}},
  booktitle = {Proceedings of the 22nd {{International Middleware Conference}}},
  author = {Copik, Marcin and Kwasniewski, Grzegorz and Besta, Maciej and Podstawski, Michal and Hoefler, Torsten},
  date = {2021},
  series = {Middleware '21},
  pages = {64--78},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3464298.3476133},
  url = {https://doi.org/10.1145/3464298.3476133},
  isbn = {978-1-4503-8534-3},
  venue = {Québec city, Canada},
  keywords = {benchmark,FaaS,function-as-a-service,serverless}
}

@inproceedings{dawXanaduMitigatingCascading2020,
  title = {Xanadu: {{Mitigating}} Cascading Cold Starts in Serverless Function Chain Deployments},
  booktitle = {Proceedings of the 21st {{International Middleware Conference}}},
  author = {Daw, Nilanjan and Bellur, Umesh and Kulkarni, Purushottam},
  date = {2020},
  series = {Middleware '20},
  pages = {356--370},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3423211.3425690},
  url = {https://doi.org/10.1145/3423211.3425690},
  abstract = {Organization of tasks as workflows are an essential feature to expand the applicability of the serverless computing framework. Existing serverless platforms are either agnostic to function chains (workflows as a composition of functions) or rely on naive provisioning and management mechanisms of the serverless framework—an example is that they provision resources after the trigger to each function in a workflow arrives thereby forcing a setup latency for each function in the workflow. In this work, we focus on mitigating the cascading cold start problem— the latency overheads in triggering a sequence of serverless functions according to a workflow specification. We first establish the nature and extent of the cascading effects in cold start situations across multiple commercial server platforms and cloud providers. Towards mitigating these cascading overheads, we design and develop several optimizations, that are built into our tool Xanadu. Xanadu offers multiple instantiation options based on the desired runtime isolation requirements and supports function chaining with or without explicit workflow specifications. Xanadu's optimizations to address the cascading cold start problem are built on speculative and just-in-time provisioning of resources. Our evaluation of the Xanadu system reveals almost complete elimination of cascading cold starts at minimal cost overheads, outperforming the available state of the art platforms. For even relatively short workflows, Xanadu reduces platform overheads by almost 18x compared to Knative and 10x compared to Apache Openwhisk.},
  isbn = {978-1-4503-8153-6},
  venue = {Delft, Netherlands},
  keywords = {Just-in-time scheduling,Serverless workflows,Speculative deployment}
}

@inproceedings{duCatalyzerSubmillisecondStartup2020,
  title = {Catalyzer: {{Sub-millisecond Startup}} for {{Serverless Computing}} with {{Initialization-less Booting}}},
  booktitle = {Proceedings of the {{Twenty-Fifth International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}},
  author = {Du, Dong and Yu, Tianyi and Xia, Yubin and Zang, Binyu and Yan, Guanglu and Qin, Chenggang and Wu, Qixuan and Chen, Haibo},
  date = {2020},
  series = {{{ASPLOS}} '20},
  pages = {467--481},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3373376.3378512},
  url = {https://doi.org/10.1145/3373376.3378512},
  abstract = {Serverless computing promises cost-efficiency and elasticity for high-productive software development. To achieve this, the serverless sandbox system must address two challenges: strong isolation between function instances, and low startup latency to ensure user experience. While strong isolation can be provided by virtualization-based sandboxes, the initialization of sandbox and application causes non-negligible startup overhead. Conventional sandbox systems fall short in low-latency startup due to their application-agnostic nature: they can only reduce the latency of sandbox initialization through hypervisor and guest kernel customization, which is inadequate and does not mitigate the majority of startup overhead.This paper proposes Catalyzer, a serverless sandbox system design providing both strong isolation and extremely fast function startup. Instead of booting from scratch, Catalyzer restores a virtualization-based function instance from a well-formed checkpoint image and thereby skips the initialization on the critical path (init-less). Catalyzer boosts the restore performance by on-demand recovering both user-level memory state and system state. We also propose a new OS primitive, sfork (sandbox fork), to further reduce the startup latency by directly reusing the state of a running sandbox instance. Fundamentally, Catalyzer removes the initialization cost by reusing state, which enables general optimizations for diverse serverless functions. The evaluation shows that Catalyzer reduces startup latency by orders of magnitude, achieves {$<$} 1ms latency in the best case, and significantly reduces the end-to-end latency for real-world workloads. Catalyzer has been adopted by Ant Financial, and we also present lessons learned from industrial development.},
  isbn = {978-1-4503-7102-5},
  venue = {Lausanne, Switzerland},
  keywords = {checkpoint and restore,operating system,serverless computing,startup latency}
}

@article{eismannReviewServerlessUse2020,
  title = {A {{Review}} of {{Serverless Use Cases}} and Their {{Characteristics}}},
  author = {Eismann, Simon and Scheuner, Joel and Eyk, Erwin Van and Schwinger, Maximilian and Grohmann, Johannes and Herbst, Nikolas and Abad, Cristina L. and Iosup, Alexandru},
  date = {2020},
  journaltitle = {CoRR},
  volume = {abs/2008.11110},
  eprint = {2008.11110},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/2008.11110}
}

@online{ellisOpenFaaS2024,
  title = {{{OpenFaaS}}},
  author = {Ellis, Alex},
  date = {2024},
  url = {https://github.com/openfaas/faas}
}

@online{EventarcOverview,
  title = {Eventarc Overview},
  url = {https://cloud.google.com/eventarc/docs/overview},
  urldate = {2024-06-04},
  langid = {english},
  organization = {Google Cloud}
}

@online{EventListenerAmazon,
  title = {Event {{Listener}} - {{Amazon EventBridge}} - {{AWS}}},
  url = {https://aws.amazon.com/eventbridge/},
  urldate = {2024-06-04},
  abstract = {Amazon EventBridge is a serverless event bus that ingests data from your own apps, SaaS apps, and AWS services and routes that data to targets.},
  langid = {american},
  organization = {Amazon Web Services, Inc.},
  file = {/Users/oli/Zotero/storage/HAQ4LRL3/eventbridge.html}
}

@online{foundationNodeJS2024,
  title = {{{NodeJS}}},
  author = {Foundation, OpenJS},
  date = {2024},
  url = {https://nodejs.org/}
}

@online{foundationNodeJsEvent2024,
  title = {The {{Node}}.Js {{Event Loop}}, {{Timers}}, and Process.{{nextTick}}()},
  author = {Foundation, OpenJS},
  date = {2024},
  url = {https://nodejs.org/en/guides/event-loop-timers-and-nexttick}
}

@inproceedings{gadepalliChallengesOpportunitiesEfficient2019,
  title = {Challenges and {{Opportunities}} for {{Efficient Serverless Computing}} at the {{Edge}}},
  booktitle = {2019 38th {{Symposium}} on {{Reliable Distributed Systems}} ({{SRDS}})},
  author = {Gadepalli, Phani Kishore and Peach, Gregor and Cherkasova, Ludmila and Aitken, Rob and Parmer, Gabriel},
  date = {2019},
  pages = {261--2615},
  doi = {10.1109/SRDS47363.2019.00036}
}

@inproceedings{gadepalliSledgeServerlessfirstLightweight2020,
  title = {Sledge: A {{Serverless-first}}, {{Light-weight Wasm Runtime}} for the {{Edge}}},
  booktitle = {Proceedings of the 21st {{International Middleware Conference}}},
  author = {Gadepalli, Phani Kishore and McBride, Sean and Peach, Gregor and Cherkasova, Ludmila and Parmer, Gabriel},
  date = {2020},
  series = {Middleware '20},
  pages = {265--279},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3423211.3425680},
  url = {https://doi.org/10.1145/3423211.3425680},
  abstract = {Emerging IoT applications with real-time latency constraints require new data processing systems operating at the Edge. Serverless computing offers a new compelling paradigm, where a user can execute a small application without handling the operational issues of server provisioning and resource management. Despite a variety of existing commercial and open source serverless platforms (utilizing VMs and containers), these solutions are too heavy-weight for a resource-constrained Edge systems (due to large memory footprint and high invocation time). Moreover, serverless workloads that focus on per-client, short-running computations are not an ideal fit for existing general purpose computing systems.In this paper, we present the design and implementation of Sledge – a novel and efficient WebAssembly-based serverless framework for the Edge. Sledge is optimized for supporting unique properties of serverless workloads: the need for high density multi-tenancy, low startup time, bursty client request rates, and short-lived computations. Sledge is designed for these constraints by offering (i) optimized scheduling policies and efficient work-distribution for short-lived computations, and (ii) a light-weight function isolation model implemented using our own WebAssembly-based software fault isolation infrastructure. These lightweight sandboxes are designed to support high-density computation: with fast startup and teardown times to handle high client request rates. An extensive evaluation of Sledge with varying workloads and real-world serverless applications demonstrates the effectiveness of the designed serverless-first runtime for the Edge. Sledge supports up to 4 times higher throughput and 4 times lower latencies compared to Nuclio, one of the fastest open-source serverless frameworks.},
  isbn = {978-1-4503-8153-6},
  venue = {Delft, Netherlands},
  keywords = {Edge computing,IoT,serverless,WebAssembly}
}

@inproceedings{garcialopezComparisonFaaSOrchestration2018,
  title = {Comparison of {{FaaS Orchestration Systems}}},
  booktitle = {2018 {{IEEE}}/{{ACM International Conference}} on {{Utility}} and {{Cloud Computing Companion}} ({{UCC Companion}})},
  author = {García López, Pedro and Sánchez-Artigas, Marc and París, Gerard and Barcelona Pons, Daniel and Ruiz Ollobarren, Álvaro and Arroyo Pinto, David},
  date = {2018},
  pages = {148--153},
  doi = {10.1109/UCC-Companion.2018.00049},
  keywords = {Amazon Step Functions,Azure Durable Functions,Cloud computing,Computer architecture,DSL,FAA,Function Composition,IBM Composer,Measurement,Orchestration,Packaging,Programming,Serverless,Software}
}

@inproceedings{ghoshCachingTechniquesImprove2020,
  title = {Caching {{Techniques}} to {{Improve Latency}} in {{Serverless Architectures}}},
  booktitle = {2020 {{International Conference}} on {{COMmunication Systems}} \& {{NETworkS}} ({{COMSNETS}})},
  author = {Ghosh, Bishakh Chandra and Addya, Sourav Kanti and Somy, Nishant Baranwal and Nath, Shubha Brata and Chakraborty, Sandip and Ghosh, Soumya K},
  date = {2020},
  pages = {666--669},
  doi = {10.1109/COMSNETS48256.2020.9027427}
}

@incollection{goniwadaCloudNativeArchitecture2022,
  title = {Cloud {{Native Architecture}} and {{Design Patterns}}},
  booktitle = {Cloud {{Native Architecture}} and {{Design}}: {{A Handbook}} for {{Modern Day Architecture}} and {{Design}} with {{Enterprise-Grade Examples}}},
  author = {Goniwada, Shivakumar R.},
  editor = {Goniwada, Shivakumar R.},
  date = {2022},
  pages = {127--187},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/978-1-4842-7226-8_4},
  url = {https://doi.org/10.1007/978-1-4842-7226-8_4},
  urldate = {2024-06-04},
  abstract = {The Pattern Language is an organized and coherent set of patterns, each of which describes a problem and the core of a solution that can be used in many ways within a specific field of expertise.},
  isbn = {978-1-4842-7226-8},
  langid = {english},
  file = {/Users/oli/Zotero/storage/NUKTQQ99/Goniwada - 2022 - Cloud Native Architecture and Design Patterns.pdf}
}

@online{googleGoogleCloudFunctions2024,
  title = {Google {{Cloud Functions}}},
  author = {{Google}},
  date = {2024},
  url = {https://cloud.google.com/functions}
}

@online{googleWhatV82024,
  title = {What Is {{V8}}?},
  author = {{Google}},
  date = {2024},
  url = {https://v8.dev/}
}

@online{gregorpeachAWsm2024,
  title = {{{aWsm}}},
  author = {family=Gregor Peach, given=et, prefix=al., useprefix=false},
  date = {2024},
  url = {https://github.com/gwsystems/aWsm}
}

@article{hellersteinServerlessComputingOne2018,
  title = {Serverless {{Computing}}: {{One Step Forward}}, {{Two Steps Back}}},
  author = {Hellerstein, Joseph M. and Faleiro, Jose M. and Gonzalez, Joseph E. and Schleier-Smith, Johann and Sreekanti, Vikram and Tumanov, Alexey and Wu, Chenggang},
  date = {2018},
  journaltitle = {CoRR},
  volume = {abs/1812.03651},
  eprint = {1812.03651},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1812.03651}
}

@inproceedings{hilleyCloudComputingTaxonomy2009,
  title = {Cloud {{Computing}}: {{A Taxonomy}} of {{Platform}} and {{Infrastructure-level Offerings}}},
  shorttitle = {Cloud {{Computing}}},
  author = {Hilley, David},
  date = {2009-04-01},
  url = {https://www.semanticscholar.org/paper/Cloud-Computing%3A-A-Taxonomy-of-Platform-and-Hilley/7d778ad2dd3b79164e1c2a09636cb9f024f4fd9b},
  urldate = {2024-06-04},
  abstract = {Semantic Scholar extracted view of "Cloud Computing: A Taxonomy of Platform and Infrastructure-level Offerings" by David Hilley}
}

@inproceedings{hoeferTaxonomyCloudComputing2010,
  title = {Taxonomy of Cloud Computing Services},
  booktitle = {2010 {{IEEE Globecom Workshops}}},
  author = {Hoefer, C. N. and Karagiannis, G.},
  date = {2010-12},
  pages = {1345--1350},
  issn = {2166-0077},
  doi = {10.1109/GLOCOMW.2010.5700157},
  url = {https://ieeexplore.ieee.org/abstract/document/5700157},
  urldate = {2024-06-04},
  abstract = {Cloud computing is a highly discussed topic, and many big players of the software industry are entering the development of cloud services. Several companies want to explore the possibilities and benefits of cloud computing, but with the amount of cloud computing services increasing quickly, the need for a taxonomy framework rises. This paper describes the available cloud computing services, and proposes a tree-structured taxonomy based on their characteristics, to easily classify cloud computing services making it easier to compare them.},
  eventtitle = {2010 {{IEEE Globecom Workshops}}},
  keywords = {Characteristics,cloud computing,Cloud computing,Google,Open source software,Security,Standards,taxonomy,Taxonomy},
  file = {/Users/oli/Zotero/storage/5EEIMYWL/Hoefer and Karagiannis - 2010 - Taxonomy of cloud computing services.pdf;/Users/oli/Zotero/storage/2YX37L4K/5700157.html}
}

@online{ibmIBMCloudFunctions2024,
  title = {{{IBM Cloud Functions}}},
  author = {{IBM}},
  date = {2024},
  url = {https://cloud.ibm.com/docs/openwhisk}
}

@online{ibmWhatFaaSFunctionasaService2024,
  title = {What Is {{FaaS}} ({{Function-as-a-Service}})? | {{IBM}}},
  author = {{IBM}},
  date = {2024},
  url = {https://www.ibm.com/topics/faas}
}

@online{incDeno2024,
  title = {Deno},
  author = {Inc, Deno Land},
  date = {2024},
  url = {https://deno.com/}
}

@online{IntroducingGoogleApp,
  title = {Introducing {{Google App Engine}} + Our New Blog},
  url = {https://cloudplatform.googleblog.com/2008/04/introducing-google-app-engine-our-new.html},
  urldate = {2024-06-04},
  abstract = {Posted by Paul McDonald, Product Manager   At tonight's Campfire One  we launched a preview release  of Google App Engine -- a developer too...},
  langid = {english},
  organization = {Google Cloud Platform Blog},
  file = {/Users/oli/Zotero/storage/MENSAJI8/introducing-google-app-engine-our-new.html}
}

@article{jainStudyFirecrackerMicroVM2020,
  title = {Study of {{Firecracker MicroVM}}},
  author = {Jain, Madhur},
  date = {2020},
  journaltitle = {CoRR},
  volume = {abs/2005.12821},
  eprint = {2005.12821},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/2005.12821}
}

@article{jonasCloudProgrammingSimplified2019,
  title = {Cloud {{Programming Simplified}}: {{A Berkeley View}} on {{Serverless Computing}}},
  author = {Jonas, Eric and Schleier-Smith, Johann and Sreekanti, Vikram and Tsai, Chia-che and Khandelwal, Anurag and Pu, Qifan and Shankar, Vaishaal and Carreira, João and Krauth, Karl and Yadwadkar, Neeraja Jayant and Gonzalez, Joseph and Popa, Raluca A. and Stoica, Ion and Patterson, David A.},
  date = {2019},
  journaltitle = {ArXiv},
  volume = {abs/1902.03383},
  url = {https://api.semanticscholar.org/CorpusID:60440467}
}

@inproceedings{jonasOccupyCloudDistributed2017,
  title = {Occupy the Cloud: Distributed Computing for the 99\%},
  booktitle = {Proceedings of the 2017 {{Symposium}} on {{Cloud Computing}}},
  author = {Jonas, Eric and Pu, Qifan and Venkataraman, Shivaram and Stoica, Ion and Recht, Benjamin},
  date = {2017},
  series = {{{SoCC}} '17},
  pages = {445--451},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3127479.3128601},
  url = {https://doi.org/10.1145/3127479.3128601},
  abstract = {Distributed computing remains inaccessible to a large number of users, in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model, many users are still left to struggle with complex cluster management and configuration tools, even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users, eliminating cluster management overhead, fulfilling the promise of elasticity. Furthermore, using our prototype implementation, PyWren, we show that this model is general enough to implement a number of distributed computing models, such as BSP, efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage, we suggest that stateless functions are a natural fit for data processing in future computing environments.},
  isbn = {978-1-4503-5028-0},
  venue = {Santa Clara, California},
  keywords = {AWS lambda,distributed computing,PyWren,serverless}
}

@inproceedings{kotniFaastlaneAcceleratingFunctionasaService2021,
  title = {Faastlane: {{Accelerating Function-as-a-Service Workflows}}},
  booktitle = {2021 {{USENIX Annual Technical Conference}} ({{USENIX ATC}} 21)},
  author = {Kotni, Swaroop and Nayak, Ajay and Ganapathy, Vinod and Basu, Arkaprava},
  date = {2021-07},
  pages = {805--820},
  publisher = {USENIX Association},
  url = {https://www.usenix.org/conference/atc21/presentation/kotni},
  isbn = {978-1-939133-23-6}
}

@inproceedings{mahmoudiOptimizingServerlessComputing2019,
  title = {Optimizing Serverless Computing: Introducing an Adaptive Function Placement Algorithm},
  booktitle = {Proceedings of the 29th {{Annual International Conference}} on {{Computer Science}} and {{Software Engineering}}},
  author = {Mahmoudi, Nima and Lin, Changyuan and Khazaei, Hamzeh and Litoiu, Marin},
  date = {2019},
  series = {{{CASCON}} '19},
  pages = {203--213},
  publisher = {IBM Corp.},
  location = {USA},
  abstract = {The main concept behind serverless computing is to build and run applications without the need for server management. It refers to a fine-grained deployment model where applications, comprising of one or more functions, are uploaded to a platform and then executed, scaled, and billed in response to the exact demand needed at the moment. While elite cloud vendors such as Amazon, Google, Microsoft, and IBM are now providing serverless computing, their approach for the placement of functions, i.e. associated container or sandbox, on servers is oblivious to the workload which may lead to poor performance and/or higher operational cost for software owners. In this paper, using statistical machine learning, we design and evaluate an adaptive function placement algorithm which can be used by serverless computing platforms to optimize the performance of running functions while minimizing the operational cost. Given a fixed amount of resources, our smart spread function placement algorithm results in higher performance compared to existing approaches; this will be achieved by maintaining the users' desired quality of service for a longer time which prevents premature scaling of the cloud resources. Extensive experimental studies revealed that the proposed adaptive function placement algorithm can be easily adopted by serverless computing providers and integrated to container orchestration platforms without introducing any limiting side effects.},
  venue = {Toronto, Ontario, Canada},
  keywords = {container placement algorithms,machine learning,optimization,predictive performance modeling,serverless computing}
}

@inproceedings{menageAddingGenericProcess2010,
  title = {Adding {{Generic Process Containers}} to the {{Linux Kernel}}},
  author = {Menage, Paul},
  date = {2010},
  url = {https://api.semanticscholar.org/CorpusID:195183412}
}

@article{michaelMSWasmSoundlyEnforcing2023,
  title = {{{MSWasm}}: {{Soundly Enforcing Memory-Safe Execution}} of {{Unsafe Code}}},
  author = {Michael, Alexandra E. and Gollamudi, Anitha and Bosamiya, Jay and Johnson, Evan and Denlinger, Aidan and Disselkoen, Craig and Watt, Conrad and Parno, Bryan and Patrignani, Marco and Vassena, Marco and Stefan, Deian},
  date = {2023-01},
  journaltitle = {Proc. ACM Program. Lang.},
  volume = {7},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3571208},
  url = {https://doi.org/10.1145/3571208},
  abstract = {Most programs compiled to WebAssembly (Wasm) today are written in unsafe languages like C and C++. Unfortunately, memory-unsafe C code remains unsafe when compiled to Wasm—and attackers can exploit buffer overflows and use-after-frees in Wasm almost as easily as they can on native platforms. Memory- Safe WebAssembly (MSWasm) proposes to extend Wasm with language-level memory-safety abstractions to precisely address this problem. In this paper, we build on the original MSWasm position paper to realize this vision. We give a precise and formal semantics of MSWasm, and prove that well-typed MSWasm programs are, by construction, robustly memory safe. To this end, we develop a novel, language-independent memory-safety property based on colored memory locations and pointers. This property also lets us reason about the security guarantees of a formal C-to-MSWasm compiler—and prove that it always produces memory-safe programs (and preserves the semantics of safe programs). We use these formal results to then guide several implementations: Two compilers of MSWasm to native code, and a C-to-MSWasm compiler (that extends Clang). Our MSWasm compilers support different enforcement mechanisms, allowing developers to make security-performance trade-offs according to their needs. Our evaluation shows that on the PolyBenchC suite, the overhead of enforcing memory safety in software ranges from 22\% (enforcing spatial safety alone) to 198\% (enforcing full memory safety), and 51.7\% when using hardware memory capabilities for spatial safety and pointer integrity. More importantly, MSWasm’s design makes it easy to swap between enforcement mechanisms; as fast (especially hardware-based) enforcement techniques become available, MSWasm will be able to take advantage of these advances almost for free.},
  issue = {POPL},
  keywords = {Memory-safety,Secure Compilation,Semantics,WebAssembly}
}

@online{mozillaSpiderMonkeyJavaScriptWebAssembly2024,
  title = {{{SpiderMonkey JavaScript}}/{{WebAssembly Engine}}},
  author = {{Mozilla}},
  date = {2024},
  url = {https://spidermonkey.dev/}
}

@inproceedings{mvondoOFCOpportunisticCaching2021,
  title = {{{OFC}}: An Opportunistic Caching System for {{FaaS}} Platforms},
  booktitle = {Proceedings of the {{Sixteenth European Conference}} on {{Computer Systems}}},
  author = {Mvondo, Djob and Bacou, Mathieu and Nguetchouang, Kevin and Ngale, Lucien and Pouget, Stéphane and Kouam, Josiane and Lachaize, Renaud and Hwang, Jinho and Wood, Tim and Hagimont, Daniel and De Palma, Noël and Batchakui, Bernabé and Tchana, Alain},
  date = {2021},
  series = {{{EuroSys}} '21},
  pages = {228--244},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3447786.3456239},
  url = {https://doi.org/10.1145/3447786.3456239},
  abstract = {Cloud applications based on the "Functions as a Service" (FaaS) paradigm have become very popular. Yet, due to their stateless nature, they must frequently interact with an external data store, which limits their performance. To mitigate this issue, we introduce OFC, a transparent, vertically and horizontally elastic in-memory caching system for FaaS platforms, distributed over the worker nodes. OFC provides these benefits cost-effectively by exploiting two common sources of resource waste: (i) most cloud tenants overprovision the memory resources reserved for their functions because their footprint is non-trivially input-dependent and (ii) FaaS providers keep function sandboxes alive for several minutes to avoid cold starts. Using machine learning models adjusted for typical function input data categories (e.g., multimedia formats), OFC estimates the actual memory resources required by each function invocation and hoards the remaining capacity to feed the cache. We build our OFC prototype based on enhancements to the OpenWhisk FaaS platform, the Swift persistent object store, and the RAM-Cloud in-memory store. Using a diverse set of workloads, we show that OFC improves by up to 82 \% and 60 \% respectively the execution time of single-stage and pipelined functions.},
  isbn = {978-1-4503-8334-9},
  venue = {Online Event, United Kingdom},
  keywords = {cache,cloud computing,functions as a service (FaaS),latency,serverless}
}

@inproceedings{oakesSOCKRapidTask2018,
  title = {{{SOCK}}: {{Rapid Task Provisioning}} with {{Serverless-Optimized Containers}}},
  booktitle = {2018 {{USENIX Annual Technical Conference}} ({{USENIX ATC}} 18)},
  author = {Oakes, Edward and Yang, Leon and Zhou, Dennis and Houck, Kevin and Harter, Tyler and Arpaci-Dusseau, Andrea and Arpaci-Dusseau, Remzi},
  date = {2018-07},
  pages = {57--70},
  publisher = {USENIX Association},
  location = {Boston, MA},
  url = {https://www.usenix.org/conference/atc18/presentation/oakes},
  isbn = {978-1-931971-44-7}
}

@inproceedings{oliverstenbomRefunctionEliminatingServerless2019,
  title = {Refunction: {{Eliminating Serverless Cold Starts Through Container Reuse}}},
  author = {Oliver Stenbom, Robert Chatley},
  date = {2019},
  url = {https://www.imperial.ac.uk/media/imperial-college/faculty-of-engineering/computing/public/1819-ug-projects/StenbomO-Refunction-Eliminating-Serverless-Cold-Starts-Through-Container-Reuse.pdf}
}

@online{OptimizingLambdasReducing,
  title = {Optimizing Lambdas - Reducing Your Bills - {{Serverless Framework}} - {{Serverless Forums}}},
  url = {https://forum.serverless.com/t/optimizing-lambdas-reducing-your-bills/4101},
  urldate = {2024-06-04},
  file = {/Users/oli/Zotero/storage/L5T3JCDK/4101.html}
}

@inproceedings{patilServerlessComputingEmergence2021,
  title = {Serverless {{Computing}} and the {{Emergence}} of {{Function-as-a-Service}}},
  booktitle = {2021 {{International Conference}} on {{Recent Trends}} on {{Electronics}}, {{Information}}, {{Communication}} \& {{Technology}} ({{RTEICT}})},
  author = {Patil, Rishabh and Chaudhery, Tanveesh Singh and Qureshi, Muhammad Ali and Sawant, Vinaya and Dalvi, Harshal},
  date = {2021-08-27},
  pages = {764--769},
  publisher = {IEEE},
  location = {Bangalore, India},
  doi = {10.1109/RTEICT52294.2021.9573962},
  url = {https://ieeexplore.ieee.org/document/9573962/},
  urldate = {2024-06-04},
  eventtitle = {2021 {{International Conference}} on {{Recent Trends}} on {{Electronics}}, {{Information}}, {{Communication}} \& {{Technology}} ({{RTEICT}})},
  isbn = {978-1-66543-559-8}
}

@online{robeceOverviewAzureEvent2024,
  title = {Overview - {{Azure Event Grid}}},
  author = {{robece}},
  date = {2024-05-21},
  url = {https://learn.microsoft.com/en-us/azure/event-grid/overview},
  urldate = {2024-06-04},
  abstract = {Learn about Event Grid's http and MQTT messaging capabilities.},
  langid = {american},
  file = {/Users/oli/Zotero/storage/XG7JCGWG/overview.html}
}

@inproceedings{sabbioniSharedMemoryApproach2021,
  title = {A {{Shared Memory Approach}} for {{Function Chaining}} in {{Serverless Platforms}}},
  booktitle = {2021 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  author = {Sabbioni, Andrea and Rosa, Lorenzo and Bujari, Armir and Foschini, Luca and Corradi, Antonio},
  date = {2021},
  pages = {1--6},
  doi = {10.1109/ISCC53001.2021.9631385}
}

@inproceedings{sampeServerlessDataAnalytics2018,
  title = {Serverless {{Data Analytics}} in the {{IBM Cloud}}},
  booktitle = {Proceedings of the 19th {{International Middleware Conference Industry}}},
  author = {Sampé, Josep and Vernik, Gil and Sánchez-Artigas, Marc and García-López, Pedro},
  date = {2018},
  series = {Middleware '18},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3284028.3284029},
  url = {https://doi.org/10.1145/3284028.3284029},
  abstract = {Unexpectedly, the rise of serverless computing has also collaterally started the "democratization" of massive-scale data parallelism. This new trend heralded by PyWren pursues to enable untrained users to execute single-machine code in the cloud at massive scale through platforms like AWS Lambda. Inspired by this vision, this industry paper presents IBM-PyWren, which continues the pioneering work begun by PyWren in this field. It must be noted that IBM-PyWren is not, however, just a mere reimplementation of PyWren's API atop IBM Cloud Functions. Rather, it is must be viewed as an advanced extension of PyWren to run broader MapReduce jobs. We describe the design, innovative features (API extensions, data discovering \& partitioning, composability, etc.) and performance of IBM-PyWren, along with the challenges encountered during its implementation.},
  isbn = {978-1-4503-6016-6},
  venue = {Rennes, France},
  keywords = {Distributed computing,IBM Cloud Functions,IBM Cloud Object Storage,PyWren,Serverless computing}
}

@inproceedings{sedefogluCostMinimizationDeploying2021,
  title = {Cost Minimization for Deploying Serverless Functions},
  booktitle = {Proceedings of the 36th {{Annual ACM Symposium}} on {{Applied Computing}}},
  author = {Sedefoğlu, Özgür and Sözer, Hasan},
  date = {2021},
  series = {{{SAC}} '21},
  pages = {83--85},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3412841.3442069},
  url = {https://doi.org/10.1145/3412841.3442069},
  abstract = {The costs of serverless functions increase proportional to the amount of memory reserved on the deployed server. However, increasing the amount of memory decreases the function execution time, which is also a factor that contributes to cost. We propose an automated approach for optimizing the amount of memory reserved for serverless functions. First, we measure the running time of a given function in various memory settings and derive a regression model. Then, we define an objective function and a set of constraints based on this regression model and the configuration space. Finally, we determine the optimal memory setting for minimizing cost. Our industrial case study shows that significant cost reductions can be achieved by accurate estimations of the impact of memory settings on runtime performance.},
  isbn = {978-1-4503-8104-8},
  venue = {Virtual Event, Republic of Korea},
  keywords = {cloud computing,cost minimization,function as a service,industrial case study,serverless computing}
}

@incollection{sehgalCostBillingPractices2023,
  title = {Cost and {{Billing Practices}} in {{Cloud}}},
  booktitle = {Cloud {{Computing}} with {{Security}} and {{Scalability}}.: {{Concepts}} and {{Practices}}},
  author = {Sehgal, Naresh Kumar and Bhatt, Pramod Chandra P. and Acken, John M.},
  editor = {Sehgal, Naresh Kumar and Bhatt, Pramod Chandra P. and Acken, John M.},
  date = {2023},
  pages = {177--195},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-07242-0_10},
  url = {https://doi.org/10.1007/978-3-031-07242-0_10},
  urldate = {2024-06-04},
  abstract = {The usage of Cloud is through a service provider, wherein the two primary stakeholders are the consumers and provider of the service. However, unlike utilities such as electricity, water, postal, or city services, the Cloud Computing services offer opportunities for many interesting and innovative provisions, which we shall discuss later in this chapter. In this section, we compare and contrast some facets of billing in traditional utility services vs. Cloud Computing.},
  isbn = {978-3-031-07242-0},
  langid = {english},
  keywords = {Auto scaling,Billing,Cloud computing,Cost,Forecasting,Load balancing,Service,SLA},
  file = {/Users/oli/Zotero/storage/RZCXBVU6/Sehgal et al. - 2023 - Cost and Billing Practices in Cloud.pdf}
}

@online{serverlessServerlessZeroFrictionServerless2024,
  title = {Serverless: {{Zero-Friction Serverless Apps On AWS Lambda}} \& {{Beyond}}},
  author = {Serverless, Inc},
  date = {2024},
  url = {https://www.serverless.com/}
}

@inproceedings{shillakerFaasmLightweightIsolation2020,
  title = {Faasm: {{Lightweight Isolation}} for {{Efficient Stateful Serverless Computing}}},
  booktitle = {2020 {{USENIX Annual Technical Conference}} ({{USENIX ATC}} 20)},
  author = {Shillaker, Simon and Pietzuch, Peter},
  date = {2020-07},
  pages = {419--433},
  publisher = {USENIX Association},
  url = {https://www.usenix.org/conference/atc20/presentation/shillaker},
  isbn = {978-1-939133-14-4}
}

@article{sreekantiCloudburstStatefulFunctionsasaService2020,
  title = {Cloudburst: {{Stateful Functions-as-a-Service}}},
  author = {Sreekanti, Vikram and Wu, Chenggang and Lin, Xiayue Charles and Schleier-Smith, Johann and Faleiro, Jose M. and Gonzalez, Joseph E. and Hellerstein, Joseph M. and Tumanov, Alexey},
  date = {2020},
  journaltitle = {CoRR},
  volume = {abs/2001.04592},
  eprint = {2001.04592},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/2001.04592}
}

@online{StateServerlessDatadog,
  title = {The {{State}} of {{Serverless}} | {{Datadog}}},
  url = {https://www.datadoghq.com/state-of-serverless/},
  urldate = {2024-06-04},
  file = {/Users/oli/Zotero/storage/FL725GWV/state-of-serverless.html}
}

@online{sumnerBun2024,
  title = {Bun},
  author = {Sumner, Jared},
  date = {2024},
  url = {https://bun.sh/}
}

@article{sussmanSCHEMEInterpreterExtended1975,
  title = {{{SCHEME}}: {{An Interpreter}} for {{Extended Lambda Calculus}}},
  shorttitle = {{{SCHEME}}},
  author = {Sussman, Gerald J. and Steele, Guy L.},
  date = {1975-12-01},
  url = {https://dspace.mit.edu/handle/1721.1/5794},
  urldate = {2024-06-04},
  abstract = {Inspired by ACTORS [Greif and Hewitt] [Smith and Hewitt], we have implemented an interpreter for a LISP-like language, SCHEME, based on the lambda calculus [Church], but extended for side effects, multiprocessing, and process synchronization. The purpose of this implementation is tutorial. We wish to: (1) alleviate the confusion caused by Micro-PLANNER, CONNIVER, etc. by clarifying the embedding of non-recursive control structures in a recursive host language like LISP. (2) explain how to use these control structures, independent of such issues as pattern matching and data base manipulation. (3) have a simple concrete experimental domain for certain issues of programming semantics and style.},
  langid = {american},
  annotation = {Accepted: 2004-10-01T20:37:06Z},
  file = {/Users/oli/Zotero/storage/5ZU5V6UU/Sussman and Steele - 1975 - SCHEME An Interpreter for Extended Lambda Calculu.pdf}
}

@unpublished{vassenaMemorySafetyPreservation2019,
  title = {Memory Safety Preservation for Webassembly},
  author = {Vassena, Marco and Patrignani, Marco},
  date = {2019},
  eprint = {1910.09586},
  eprinttype = {arxiv}
}

@book{wardleyWardleyMaps2022,
  title = {Wardley {{Maps}}},
  author = {Wardley, Simon},
  editor = {Mosior, Ben},
  date = {2022-06-17},
  publisher = {Independently published},
  abstract = {This is the story of my journey, from a bumbling and confused CEO lost in the headlights of change to having a vague idea of what I was doing. I say vague because I’m not going to make grand claims to the techniques that I discuss in this book. It is enough to say that I have found them useful over the last decade whether in finding opportunity, removing waste, helping to organise a team of people or determining the strategy for a company. Will they help you? That depends upon the context that you’re operating in but since the techniques don’t take long to learn then I’ll leave it up to the reader to discover whether they are helpful to them or not. Remember, all models are wrong but some are useful. -- Simon WardleyThis work (Wardley Maps for Print v0.2.1) is an adaption of Wardley Maps by Simon Wardley (as retrieved December 23, 2020), edited for print through careful modification of the text and layout. Priced as low as Amazon will allow.},
  isbn = {9798836808136},
  langid = {english},
  pagetotal = {626}
}

@article{wenRisePlanetServerless2023,
  title = {Rise of the {{Planet}} of {{Serverless Computing}}: {{A Systematic Review}}},
  author = {Wen, Jinfeng and Chen, Zhenpeng and Jin, Xin and Liu, Xuanzhe},
  date = {2023-07},
  journaltitle = {ACM Trans. Softw. Eng. Methodol.},
  volume = {32},
  number = {5},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  issn = {1049-331X},
  doi = {10.1145/3579643},
  url = {https://doi.org/10.1145/3579643},
  abstract = {Serverless computing is an emerging cloud computing paradigm, being adopted to develop a wide range of software applications. It allows developers to focus on the application logic in the granularity of function, thereby freeing developers from tedious and error-prone infrastructure management. Meanwhile, its unique characteristic poses new challenges to the development and deployment of serverless-based applications. To tackle these challenges, enormous research efforts have been devoted. This article provides a comprehensive literature review to characterize the current research state of serverless computing. Specifically, this article covers 164 articles on 17 research directions of serverless computing, including performance optimization, programming framework, application migration, multi-cloud development, testing and debugging, and so on. It also derives research trends, focus, and commonly-used platforms for serverless computing, as well as promising research opportunities.},
  keywords = {literature view,Serverless computing}
}
