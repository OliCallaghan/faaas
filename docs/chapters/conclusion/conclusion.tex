\chapter{Conclusion and Future Work}
\section{Conclusion}
\todo[inline]{Discuss what has been achieved in this project.}
\todo[inline]{Discuss the findings of the evaluation}

\section{Future Work}
\todo[inline]{Discuss future work that could be done in this area.}

A major unaddressed bottleneck of \faaas{} currently relates to the overhead of serialising and deserialising context state passed between function invocations. Whilst this is necessary in order to persist state between function invocation and handler, in the pathalogical case where a variable is declared at the start of the program, and only used at the end, the variable will need to be serialised and deserialised through each continuation.

This could be addressed in a variety of different ways, for eaxmple, a DAG of the JS program could be generated and the serialisation and deserialisation could be optimised to only include the variables that are used directly in the next continuation. Alternatively, all context could be written to a low latency cache such as Redis, and lazily loaded by continuations when they need it. This would mean that only a pointer to this data would need to be serialised and deserialised, rather than the data itself, however it would introduce additional network round-trips whenever data is accessed.

Additionaly, another bottlneck of the system is the latency whilst fetching the response time distribution parameters from the Redis cache in order to determine whether to locally invoke the asynchornous operation or delegate it to a proxy. This could be addressed by making a request directly to the proxy, which would internally determine an estimate for the asynchronous request. For instance, the database proxy could use the query estimate used by the plan optimiser to compute the probability that the function would be profitable if it split. In the case that the function should split, the proxy could then return the queue to serialise the context and the continuation to before exiting, otherwise if the split is not profitable, the proxy could just execute the query and directly return the result. This would reduce the latency by the round-trip time to the Redis cache.
