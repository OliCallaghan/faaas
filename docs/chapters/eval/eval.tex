\chapter{Evaluation}
\label{sec:evaluation}
\begin{figure}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-aws-results/assets/aws-strategy-breakdown-olap.pgf}
    \end{center}
    \caption{Cost breakdown of the \texttt{warehouse-order} OLAP function workload running on AWS Lambda (256MB). Using the adaptive split strategy, a cost reduction of 62\% is observed, whilst for always split, a cost reduction of 75\% is observed.}
\end{figure}

In this chapter, \faaas{} is evaluated in terms of its cost savings and overhead on a suite of \faas{} functions executing OLTP, OLAP and mixed workloads. In order to effectively evaluate cost savings if used today, \faas{} is deployed to AWS, and evaluated against the current AWS billing model, resulting in a cost reduction of 75\% across the OLAP benchmark suite. Following this, \faaas{} is then evaluated against a set of hypothetical billing models, in order to evaluate potential cost savings if changes to the billing model were to be made. Finally, key areas that cloud providers need to address are highlighed in order to enable more effective cost reductions across a wider range of \faas{} workloads. Throughout this chapter, we aim to provide answers to the following set of research questions:

\begin{itemize}
    \item[(q1)] To what extent can code splitting reduce costs when executing serverless functions?
    \item[(q2)] What is the overhead incurred by code splitting?
    \item[(q3)] How well does adaptive split identify optimal splitting decisions?
    \item[(q4)] What are the key areas that cloud providers need to address in order to enable more effective cost reductions across a wider range of \faas{} workloads?
\end{itemize}

\section{Benchmarking suites}
In this section we will introduce the programs which \faaas{} was evaluated against. There are a set of existing benchmark suites which exist for serverless functions, however these are typically targetted at evaluating \faas{} platforms themselves and their intrinsic properties, so focus much more closely on microbenchmarks rather than real-world workloads. Of the few suites that do exist that aim to be representative of real-world workloads, none query databases, which identified by \cite{eismannReviewServerlessUse2020}, is the second most common use-case for serverless functions after interacting with cloud storage.

Since \faaas{} specifically tackles the double-billing problem described in Section \ref{sec:double-billing-problem}, it is important to profile a wide variety of workloads that are vulnerable to this problem, alongside a set of other programs where this problem does not exist, such that the overhead of the system can be evaluated.

Therefore, a suite of evaluation programs is defined in Table \ref{table:benchmarking-suite}, that perform specific tasks, representative of real-world workloads. These programs are then executed against deployed \faaas{} functions, and the cost savings and overhead are evaluated on AWS. The evaluation programs are segregated into those which execute predominantly OLAP and OLTP workloads, and those which execute a mix of both.

\begin{table*}
\begin{tabularx}{\linewidth}{|r|c|X|c|}
    \hline
    \textbf{Program} & \textbf{ID} & \textbf{Description} & \textbf{Workload} \\
    \hline
    \verb|warehouse-report| & \verb|wh-o| & Executes TPC-H query 1 to generate a pricing report, then generates HTML report using mustache. & OLAP \\
    \hline
    \verb|warehouse-order| & \verb|wh-r| & Executes TPC-H query 2 to compute the minimum cost supplier for a part, and sends SMS (mocked) to the supplier's mobile number requesting the part.  & OLAP \\
    \hline
    \verb|warehouse-pred| & \verb|wh-p| & Executes TPC-H query 5 to compute the countries with the highest revenue, and performs a set of linear algebra operations on this data to simulate a CPU intensive workload. & OLAP \\
    \hline
    \verb|pets| & \verb|pets| & Executes a simple query to sum the pet ages of all pets with a matching name, and returns this in a response. & OLTP \\
    \hline
    \verb|bank| & \verb|bank| & Executes a simple to make a bank balance from one account to another. Returns whether the bank transfer was successful and the new balance. & OLTP \\
    \hline
    \verb|echoer| & \verb|echo| & Dummy function used as a scaffold to evaluate adaptive switch. Makes a request to an external echo service that resolves after a specified number of milliseconds. & OLTP \\
    \hline
\end{tabularx}
\caption{Suite of benchmarking programs used to evaluate \faaas{}}
\label{table:benchmarking-suite}
\end{table*}

\subsection{OLAP workloads}
In order to benchmark a representative OLAP workload, we define a set of serverless functions within the context of the warehouse described in the TPC-H benchmark. The TPC-H benchmark is a `decision support benchmark' that models a warehouse, and is widely used to evaluate the performance of OLAP databases. Whilst the purpose of this research is not to benchmarking the database itself, this benchmarking set provides a representative context for the types of queries which are executed in the OLAP domain.

\subsection{OLTP workloads}
In order to benchmark a representative OLTP workload, we define a set of serverless functions that execute OLTP queries against a database, and return the results. Specifically, we define a function that executes banking transactions within the context of a bank, and a function that queries the ages of a set of pets.

\section{Measuring cost savings}
In this section, we aim to provide provide an answer to the first research question: \blockquote{To what extent can code splitting reduce costs when executing serverless functions?}. In order to do this, we will examine which types of workloads result in cost reductions, and describe specifically how the values for total function cost of the \faaas{} deployment to AWS was measured.

Each function was deployed with each of the following strategies: \verb|adaptive|, \verb|always-proxy|, \verb|never-proxy|, \verb|use-http|, across the following range of memory sizes: 128MB, 256MB, 512MB, 1024MB. Each function was then subjected to a load test using Artillery\cite{artilleryArtilleryCloudscaleLoad}. For each of the deployed AWS Lambda functions, the total billing time and invocation count was extracted from AWS CloudWatch logs using the query defined in Listing \ref{lst:total-cost-cloudwatch-query}. The cost of execution was then calculated using the parameterised billing model defined in Section \ref{sec:faas-param-cost-model} for each function, with each resource configuration and strategy. The results of these tests are tabulated in Table \ref{table:faaas-cost-savings}.

\begin{listing}
\begin{minted}[obeytabs=true,tabsize=2]{fsharp}
fields @timestamp, @message
    | filter @message like /Billed Duration/
    | parse @message "Billed Duration: * ms" as billedDuration
    | parse @message "Memory Size: * MB" as memorySize
    | filter ispresent(billedDuration)
    | stats count(billedDuration) as totalInvocs, sum(billedDuration) as totalDuration by memorySize
\end{minted}
\caption{AWS CloudWatch query to extract billing data for a \faaas{} function}
\label{lst:total-cost-cloudwatch-query}
\end{listing}

\begin{table}
    \centering
    \begin{tabularx}{\linewidth}{|c|c|Z|}\hline
        \textbf{Program} & \textbf{Memory} & \textbf{Cost Saving} \\
        \hline
        \csvreader[column count=13,late after line=\\\hline,late after last line=\\\hline]
        {assets/tmp/faaas-bench-faaasc-artillery-results-response-times.csv}
        {1=\name, 2=\mem, 3=\costsaving}
        {\texttt{\name} & \texttt{\mem} & \costsaving}
    \end{tabularx}
    \todo[inline]{Generate this data}
    \caption{Response time latency impact of using \faaas{}}
    \label{table:faaas-cost-savings}
\end{table}

From the results, it is clear that \faaas{} is much less effective at reducing costs for OLTP workloads such as the \verb|pets| workload in Figure \ref{fig:faaas-strategy-breakdown-pets}, whilst for OLAP workloads, provides a substantial cost reduction. The cost reduction observed is dependent entirely on the response time of asynchronous requests. For higher resource allocations, cost savings are greater, and reductions can be observed for asynchronous requests with lower response times, as shown in Figure \todo{Figure varying memory, splitting strategy and program}.

\begin{figure}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-aws-results/assets/aws-strategy-breakdown.pgf}
    \end{center}
    \caption{Cost breakdown of the \texttt{pets} OLTP function workload running on AWS Lambda (256MB). Using the always split strategy, a cost increase of 75\% is observed, indicating that function splitting for short lived requests is not profitable.}
    \label{fig:faaas-strategy-breakdown-pets}
\end{figure}

\section{Measuring \faaas{} overhead}
In this section, we aim to provide an answer to the second research question: \blockquote{What is the overhead incurred by code splitting?}. In order to do this, we will evaluate how function response times are affected by introducing various parts of the \faaas{} AWS deployment, and describe specifically how figures for function response times of the \faaas{} deployment to AWS was measured. Additionally, we will provide a breakdown of billed time whilst executing a \faaas{} split function in comparison with executing the original function.

For each of the deployed functions, under the load tests, the average response time, along with other metrics were extracted from the Artillery output. The artillery experiment was executed from a home WiFi network, with a \SI{67.1}{Mbps} download, and \SI{17.1}{Mbps} upload speed. The average, and percentile response times were then calculated for each function, for each resource configuration and splitting strategy.

From the experiments, it is clear that \faaas{} introduces a high latency overhead as can be seen in \ref{table:faaas-response-time-latency}. For the \verb|warehouse-order| benchmark, this value was approximately 8 times higher compared to invoking functions directly through AWS Lambda's HTTP endpoints. By profiling which sections of the architecture consumed the most of this time, it emerged that the majority of the time is spent publishing and consuming messages from the RabbitMQ queue.

\begin{figure}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-artillery-results/assets/mean_response_times.pgf}
    \end{center}
    \caption{Artillery response times}
\end{figure}

\begin{table}
    \centering
    \begin{tabularx}{\linewidth}{|c|c|Z|Z|}\hline
        \textbf{Program} & \textbf{Strategy} & \textbf{Mean} & \textbf{p95} \\
        \hline
        \csvreader[column count=13,late after line=\\\hline,late after last line=\\\hline]
        {assets/tmp/faaas-bench-faaasc-artillery-results-response-times.csv}
        {1=\name, 13=\strat, 5=\mean, 10=\p95}
        {\texttt{\name} & \texttt{\strat} & \mean & \p95}
    \end{tabularx}
    \caption{Response time latency impact of using \faaas{}}
    \label{table:faaas-response-time-latency}
\end{table}

In order to provide a breakdown of the time spent during billed function invocation time, the AWS \faaas{} adaptor was instrumented to log times spend executing each part of the function during execution. This data was extracted from CloudWatch logs, and analysed into Table \ref{table:faaas-duration-breakdown}, and visualised for both the pets OLTP function \ref{fig:faaasc-oltp-duration-bill-breakdown}.

\begin{table}
    \centering
    \begin{tabularx}{\linewidth}{|c|c|Z|Z|}\hline
        \textbf{Program} & \textbf{Strategy} & \textbf{Mean} & \textbf{p95} \\
        \hline
        \csvreader[column count=13,late after line=\\\hline,late after last line=\\\hline]
        {assets/tmp/faaas-bench-faaasc-artillery-results-response-times.csv}
        {1=\name, 13=\strat, 5=\mean, 10=\p95}
        {\texttt{\name} & \texttt{\strat} & \mean & \p95}
    \end{tabularx}
    \todo[inline]{Generate this data}
    \caption{Duration breakdown of \faaas{} function execution}
    \label{table:faaas-duration-breakdown}
\end{table}

\begin{figure}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-aws-results/assets/aws-strategy-duration-breakdown.pgf}
    \end{center}
    \caption{OLTP \faaasc{} functions running in AWS, billing breakdown specifically of the duration segment of billed.}
    \label{fig:faaasc-oltp-duration-bill-breakdown}
\end{figure}

\section{Adaptive splitting strategy}
In this section, we aim to provide an answer to the third research question: \blockquote{How well does adaptive split identify optimal splitting decisions?} We will measure the cost of executing a variable workload using the \verb|adaptive|, \verb|never| and \verb|always| strategies over time.

The setup is as follows: we deploy the \verb|echoer| function to AWS Lambda, and use Artillery\cite{artilleryArtilleryCloudscaleLoad} to send requests at a rate of 1 request per second for 45mins to each of the strategies. Artillery is configured such that every 15mins, the timeout sent to \verb|echoer| changes from \SI{50}{\milli\second} to \SI{200}{\milli\second}, which should in turn cause the adaptive strategy to adjust it's splitting strategy once the monitor runs.

The total cost of each strategy is plotted over time in Figure \ref{fig:strategy-cost-over-time}. Whilst the adaptive strategy does not instantly adjust its strategy, after a short period of time, around 10 minutes of sustained high latency, it updates its strategy selects the optimal strategy. This value can be tuned, however since with AWS it relies on querying CloudWatch data, it is somewhat limited by the propagation delay of CloudWatch logs (typically 1-3mins). Additionally, the monitor analyses historical data in a sliding \SI{10}{\min} sliding window in order to smooth any spikes in data.

\begin{figure*}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-adaptive-results/assets/split-profitability.pgf}
    \end{center}
    \caption{Strategy cost over time.}
    \label{fig:strategy-cost-over-time}
\end{figure*}

In figure \ref{fig:strategy-decision-over-time}, the latency inferred by the monitor and actual obvserved latency is overlayed ontop of the computed probability of profitability by the function when selecting which strategy to use. During the first \SI{10}{\min}, the monitor is fitting the response time distribution to both low and high latency echoes, with the proportion of high latency echoes increasing throughout this period. As a result, it is clear from the plot that the probability of profitability is increasing during this period. There is however a brief period at 10:25, where the inferred latency diverges to a high negative value. This causes the algorithm to switch back to the never strategy briefly, before switching back to the adaptive strategy once the distribution converges back to the actual latency.

\begin{figure*}
    \begin{center}
        \input{node_modules/@faaas-bench/faaasc-adaptive-results/assets/decision-mapping.pgf}
    \end{center}
    \caption{Strategy cost over time.}
    \label{fig:strategy-decision-over-time}
\end{figure*}

\section{Conjecture time! Analysis of future research that could improve the cost-effectiveness of \faaas{}}
In this final section, we will discuss how each of the above findings help to provide an answer to the final research question: \blockquote{What are the key areas that cloud providers need to address in order to enable more effective cost reductions across a wider range of \faas{} workloads?}.

From the results of the experiments on AWS, whilst we observe a significant cost reduction in workloads executing OLAP queries, those executing predominantly OLTP queries are unable to observe any cost reductions, and actually incur penalties by performing code splitting. This is due to the high invocation costs relative to the duration costs billed when executing the function.

Since AWS is not the only provider of \faas{}, it is important to consider how this evaluation could be different if the pricing model changed in the future, or a different provider emerged with a different billing structure.

\subsection{Changes to invocation cost pricing}
Invocation costs for cloud functions are loosely coupled to the technical overhead experienced when executing a \faas{} function. Therefore, by reducing the overhead of invoking a function, it would be expected that this cost would also decrease.

Referring back to the cost model in Section \ref{sec:faas-param-cost-model}, by reducing the invocation cost, it would reduce the critical threshold which it becomes profitably to split a function across an asynchronous request.

\subsection{Reduction in startup times (cold-start and warm-start)}
From the overhead analysis, it is shown that there is considerable overhead when reinvoking a function above typical function cold starts. This is is due to a variety of factors, including the extra network round-trips to and from RabbitMQ, in addition to the additional setup costs of invoking a function with Lambda.

Since this overhead has constant time, its fiscal penalty is proportional to the function resource allocation. Similarly to the flat invocation cost, the overhead penalty occupies a larger proportion of the duration cost when the duration time is short, and thus this impacts workloads that execute OLTP queries.

Reducing this overhead would make it more cost-effective to split functions across OLTP queries as the overhead would be less significant relative to the duration cost.

\subsection{Changes to duration cost pricing}
Conversely, an increase in the duration cost $C_r$ of the cloud provider platform would make it more cost-effective to split functions across OLTP queries. The \faaasc{} AWS Lambda adaptor supports batching invocations, so by increasing the resource allocation, a Lambda can process more requests in the same invocation. This cost breakdown is shown by Figure TODO\todo{need to export this figure}.

This has the impact that the invocation cost of a single is spread evenly across all the requests in the batch. This would make it more cost-effective to split functions across OLTP queries, as the invocation cost currently dominates. On the contrary however, this model requires invocations to be batched, and typically, OLTP queries are not batched\todo{cite this somewhere, maybe I'm wrong}.

\subsection{Potential solutions which would make OLTP workloads more viable}
In this section, we discuss potential solutions which would make OLTP workloads more viable on \faas{} platforms.

\subsubsection{Voluntary release of CPU time back to the hypervisor}
As discussed in Section TODO\todo{reference to background where cloud providers typically use vms to isolate functions}, cloud providers typically use virtual machines to isolate functions. The hypervisor is responsible for scheduling CPU time to each of the virtual machines and does so fairly, based on the resource allocation of the function to be executed.

From the results of the decribed experiments, it is clear that for the proportion of the time the function is executing, functions are allocated CPU resources which they are not using. The ability to voluntarily release this CPU time back to the hypervisor would allow the hypervisor to allocate this CPU time to other functions, and thus reduce the cost of executing the function, since only the memory must be allocated for the entire duration of the function's execution.

\subsubsection{Voluntary release of memory back to the hypervisor}
Whilst releasing CPU allocation back to the hypervisor when blocked on IO could reduce the cost of executing the function, memory would still need to be billed since it occupies memory that another function could be using. In the case that a function is blocked on IO, depending on the disk latency, it could be more cost effective to write the blocked function's memory to swap during the period that it is blocked, and then load the function back into memory once the response has arrived, and the node has capacity to continue execution of the function.

This would have the impact of increasing latency, as the function would need to perform a write-read cycle to and from disk, in addition to waiting until the hypervisor has capacity to load the function back into memory. This would however allow functions to be billed more accurately based on CPU time and memory that they have utilised.

We propose a short experiment in order to assess the viability of this in AWS Lambda. By inspecting the CloudWatch logs from executing the experiment benchmarks, we observe that the average memory consumption for all the NodeJS functions was approximately \SI{108}{\mega\byte}. Since we cannot know the specifics of the disk used by the instances running the hypervisor to execute Lambda functions, we will assume that the write speed to the EFS (Elastic File System) from the Lambda environment is representative of the disk speed of the hypervisor. We deploy a simple function that writes and then reads a \SI{108}{\mega\byte} file of random data to and from EFS, and measure the time taken to perform this operation. This file is to be representative of uncompressed memory allocated to the MicroVM that is to be written to swap during a blocked IO operation. The results of this are shown in Figure \todo{run EFS IO benchmark}.

In order to achieve this technically, the operating system could notify the hypervisor that the function is blocked on IO when the operation system recieves an \verb|epoll\_wait| system call. The main difficulty with this approach would likely be the issue of correctly predicting when a call to \verb|epoll\_wait| would cause the function to yield for a long enough duration for it to be worth the hypervisor to swap the function out to disk.

Therefore, it may be more effective to implement support for this at a language level, whereby the language runtime would notify the hypervisor that the function is blocked on IO, and that the hypervisor should swap the function out to disk. If this occurs at the language level, then it would have access to context around the asynchronous IO operation, and could use this to predict its duration.

\subsubsection{Function continuation execution within the database}
We have so far focused on potential solutions that would allow for better resource utilisation of the hypervisor. Whilst an important component to the solution, it does not address the issues of latency encountered by performing the AWS Lambda slotting algorithm for each continuation. By formalising serverless functions as handlers which return continuations in Section \todo{reference back to continuations}, we could pass the continuation directly to the database to execute after the query has been completed. This however still relies on low invocation costs in order to be cost effective.

Mainstream cloud providers typically use either container based isolation or VM based isolation, which both have relatively high invocation overhead. Other isolation mechanisms, such as the WASM isolation methods described in Section \todo{Refernce back to WASM isolation section in background}, have the potential to reduce invocation overhead, allowing continuations to be executed with a much lower cost penalty.

By embedding a WASM runtime into the database, it could enable execution of the continuations reutrned by \faaasc{} handlers directly inside the database.
