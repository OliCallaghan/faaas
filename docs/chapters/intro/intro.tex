% Introduction
\chapter{Introduction}

\faasxlong{} provides an abstraction over application development, decomposing programs into isolated units called `functions', which are invoked by events such as HTTP requests, or messages received from a message bus.

In these environments, `functions' are commonly implemented as containers running on top of a runtime; when these containers are awaiting I/O such as network requests, resources are still allocated, used to determine whether execution can continue.

This research aims to yield control back to the runtime from these `functions' whilst awaiting asynchronous operations to complete, allowing useful work to be scheduled by the runtime.

% Motivation
\section{Motivation}
\begin{figure}
    \begin{center}
        \input{node_modules/@faaas/perf-v8-event-loop-results/assets/faas-profile-waiting-on-io.pgf}
    \end{center}
    \caption{\faas{} function execution profile}
\end{figure}

% Syscall Calls Breakdown
\begin{figure}
    \begin{center}
        \input{node_modules/@faaas/perf-v8-event-loop-results/assets/faas-profile-strace-calls.pgf}
    \end{center}
    \caption{\faas{} petstore syscall calls profile}
\end{figure}

% Syscall Time Breakdown
\begin{figure}
    \begin{center}
        \input{node_modules/@faaas/perf-v8-event-loop-results/assets/faas-profile-strace-time.pgf}
    \end{center}
    \caption{\faas{} petstore syscall time profile}
\end{figure}

% PProf Sample from PetStore PutPet Function
\begin{figure*}
    \begin{center}
        \begin{tikzpicture}[scale = 0.75, every node/.style={scale=0.75}]
            \input{node_modules/@faaas/perf-v8-event-loop-results-pprof/assets/faas-profile-pprof-put-pet.pgf}
        \end{tikzpicture}
    \end{center}
    \caption{\faas{} petstore PutPet pprof sample}
\end{figure*}


\faaslong{} has become increasingly more common amongst system architectures since the introduction of AWS Lambda\cite{aws-lambda} in 2014, with developers citing cost, scalability, and ease of development as the most important factors\cite{review-of-serverless-use-cases-and-characteristics}.

Typical \faas{} workloads can be characterised as `glue', most commonly handling HTTP requests and interacting with a form of persistent storage --- in fact, around 50\% of all serverless functions fall into this category\cite{review-of-serverless-use-cases-and-characteristics}.

\faas{} architectures generally tend to decrease costs, achieving this by using a fine-grained billing model, charging per invocation, and for compute and memory allocations in subsecond increments over the duration of execution, ensuring wasted resources are released back to the cloud provider once a function terminates.

The resolution of the billing model however extends only to the level of granularity of functions, whereby resources are allocated for the entire lifetime of the function's execution. This is particularly important when considering that the serverless suffers from additional latency when accessing persistent storage, for example, the average latency between AWS Lambda and DynamoDB is usually \qtyrange{60}{90}{\ms}\cite{caching-techniques-improve-latency-serverless}.

Since the median execution time for serverless functions lies between milliseconds and a second\cite{review-of-serverless-use-cases-and-characteristics}, this latency accounts for a significant proportion of time when resources are allocated and unused during function execution time. Developers are charged for this time, and cannot temporarily yield resources back to the host until the asynchronous action completes.
